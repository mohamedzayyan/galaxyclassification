{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./pytorch_sol2/')\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, time, copy, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pickle\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import *\n",
    "from GalaxiesDataset import *\n",
    "from pytorchtools import EarlyStopping\n",
    "from myGZ2_hubble import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove = []\n",
    "x = pd.read_csv('./t/gz2_hub.csv')\n",
    "for i in x['asset_id']:\n",
    "    if not os.path.isfile('./images_training_rev1/images/{}.jpg'.format(i)):\n",
    "        remove.append(i)\n",
    "x[~x['asset_id'].isin(remove)].to_csv('usethis.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = transforms.Compose([\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "        transforms.Resize((105, 105)),\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                             transforms.RandomRotation(degrees=(0,360)),\n",
    "                             transforms.RandomVerticalFlip(p=0.5),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                  std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.Resize((105, 105)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.read_csv('./t/training_solutions_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds = GalaxiesDataset(TRAIN_DIR, TRAIN_CSV, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/images_training_rev1/images/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat\n",
       "0    9\n",
       "1   10\n",
       "2    0\n",
       "3   10\n",
       "4    9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl=train_ds.classes_frame['hubble_type'].astype('category').cat.codes.tolist()\n",
    "temp = pd.DataFrame(cl,columns=['cat'])\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(temp.values)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "np.arange(len(y)),\n",
    "test_size=0.4,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y)\n",
    "\n",
    "valid_idx, test_idx= train_test_split(\n",
    "np.arange(len(y[valid_idx])),\n",
    "test_size=0.5,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239573"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape[0] + valid_idx.shape[0] +test_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 239573 Train_dl: 3594 Validation_dl: 1198 Unseen dl: 1198 \n"
     ]
    }
   ],
   "source": [
    "size = len(train_ds)\n",
    "indices = list(range(size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * size))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "test_split = int(np.floor(VALIDATION_SPLIT * len(train_indices)))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = train_indices[test_split:], train_indices[:test_split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler   = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=0,\n",
    "                                                 sampler=train_sampler)\n",
    "val_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=0,\n",
    "                                                 sampler=val_sampler)\n",
    "unseen_dl = DataLoader(train_ds,batch_size=BATCH_SIZE, num_workers=0,\n",
    "                                                 sampler=test_sampler)\n",
    "print(\"Total: {} Train_dl: {} Validation_dl: {} Unseen dl: {} \".format(size, len(train_dl),                                                                    \n",
    "                                                              len(val_dl),\n",
    "                                                              len(unseen_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239573"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices) + len(val_indices) + len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 'val' if only want to evaluate, 'train' allows you to train the model\n",
    "train_or_val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_or_val == 'train':\n",
    "    model = torch.load('./models/gz2_resnet50')\n",
    "if train_or_val == 'val':\n",
    "    model = torch.load('./models/gz2_hubble')\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.00005)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=3,threshold=0.0001,factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz_hub = GZ2_hubble(train_dl, val_dl, unseen_dl, model, optimizer, scheduler, criterion,device=device,BATCH_SIZE=BATCH_SIZE)\n",
    "if train_or_val == 'train':\n",
    "    gz_hub.train(n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on unseen test set beginning:\n",
      "Unseen accuracy: 68.17698006887196\n",
      "Unseen + weighted f1 score: 0.6906027006809564\n",
      "Confusion matrix:\n",
      "[[7843  301    1    4    0    0   63   20    0  348  158]\n",
      " [ 759 7938  136    1    8    0  112   66    0  408  366]\n",
      " [  13  231 1010    0  348    0    6   12    0   83  211]\n",
      " [  46    9    0   16    0    0    1    0    0   45    2]\n",
      " [   2   36  264    0 2932    0   24   32    0   71  195]\n",
      " [   2   10    4    0    0    0    8    1    0    5    2]\n",
      " [ 228  293   33    2   40    0 2138  300    0  607  169]\n",
      " [ 141  281   38    1   75    0  870 2392    0  211 1072]\n",
      " [  22   15    0    0    3    0    0    2    0   42   13]\n",
      " [1089  924   70    0   62    0  301   67    0 2659  661]\n",
      " [ 601  903  121    2  119    0  126  542    0  788 5739]]\n"
     ]
    }
   ],
   "source": [
    "#For unweighted f1 score with percentage confusion matrix ...\n",
    "#gz_hub.show_cf(f1_='notWeighted', cf_type='percentages')\n",
    "\n",
    "#For weighted f1 score with numbers confusion matrix ...\n",
    "gz_hub.show_cf(f1_ = 'weighted', cf_type='numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
