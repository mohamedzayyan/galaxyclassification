{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip uninstall -y scikit-learn\n",
    "!pip uninstall -y pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install scikit-learn==0.21.1\n",
    "#!pip install pandas==0.24.2\n",
    "#!pip3 install pandas_ml \n",
    "#!pip3 install pytorch_metric_learning \n",
    "!pip3 install faiss-cpu faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/floyd/home',\n",
       " '/usr/local/lib/python37.zip',\n",
       " '/usr/local/lib/python3.7',\n",
       " '/usr/local/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.7/site-packages',\n",
       " '/usr/local/lib/python3.7/site-packages/xgboost-1.0.2-py3.7.egg',\n",
       " '/usr/local/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " 'pytorch_sol2/']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('pytorch_sol2/')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from config import *\n",
    "from GalaxiesDataset import *\n",
    "from rsa_loader import *\n",
    "from efigi_loader import *\n",
    "from pytorchtools import EarlyStopping\n",
    "from myEfigiLSCE import *\n",
    "\n",
    "import pickle\n",
    "from label_smoothing import LabelSmoothingCrossEntropy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KowIJ5ipz4Ef"
   },
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers, regularizers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zs1TiAevzPed"
   },
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.Resize((105, 105)),\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                             transforms.RandomRotation(degrees=(0,360)),\n",
    "                             transforms.RandomVerticalFlip(p=0.5),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                  std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transformations = transforms.Compose([transforms.Resize((105, 105)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FOKq8Awu5FUa"
   },
   "outputs": [],
   "source": [
    "#efigi_dir = base_path + '/datasets/efigi/pics/png/'\n",
    "#\n",
    "#efigi_csv = base_path + '/classes/efigi_model.csv\n",
    "#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8q8PZYkJzytk"
   },
   "outputs": [],
   "source": [
    "train_ds = GalaxiesDataset_efigi(EFIGI_DIR, EFIGI_CSV, transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pgc_name</th>\n",
       "      <th>full_pgc_name</th>\n",
       "      <th>hubb</th>\n",
       "      <th>E</th>\n",
       "      <th>Irr</th>\n",
       "      <th>S0</th>\n",
       "      <th>SBa</th>\n",
       "      <th>SBb</th>\n",
       "      <th>SBc</th>\n",
       "      <th>Sa</th>\n",
       "      <th>Sb</th>\n",
       "      <th>Sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGC 281</td>\n",
       "      <td>PGC0000281</td>\n",
       "      <td>Sa</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGC 282</td>\n",
       "      <td>PGC0000282</td>\n",
       "      <td>SBc</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PGC 1841</td>\n",
       "      <td>PGC0001841</td>\n",
       "      <td>SBa</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PGC 3584</td>\n",
       "      <td>PGC0003584</td>\n",
       "      <td>Sb</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PGC 635</td>\n",
       "      <td>PGC0000635</td>\n",
       "      <td>SBa</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pgc_name full_pgc_name hubb       E     Irr      S0     SBa     SBb  \\\n",
       "0  PGC 281        PGC0000281   Sa  0.0125  0.0125  0.0125  0.0125  0.0125   \n",
       "1  PGC 282        PGC0000282  SBc  0.0125  0.0125  0.0125  0.0125  0.0125   \n",
       "2  PGC 1841       PGC0001841  SBa  0.0125  0.0125  0.0125  0.9000  0.0125   \n",
       "3  PGC 3584       PGC0003584   Sb  0.0125  0.0125  0.0125  0.0125  0.0125   \n",
       "4  PGC 635        PGC0000635  SBa  0.0125  0.0125  0.0125  0.9000  0.0125   \n",
       "\n",
       "      SBc      Sa      Sb      Sc  \n",
       "0  0.0125  0.9000  0.0125  0.0125  \n",
       "1  0.9000  0.0125  0.0125  0.0125  \n",
       "2  0.0125  0.0125  0.0125  0.0125  \n",
       "3  0.0125  0.0125  0.9000  0.0125  \n",
       "4  0.0125  0.0125  0.0125  0.0125  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def change(col):\n",
    "cols = train_ds.classes_frame.columns.tolist()[3:]\n",
    "K = 9\n",
    "epsilon = 0.1\n",
    "for col in cols:\n",
    "    allz = np.where(train_ds.classes_frame.loc[:, col] == 0)[0].tolist()\n",
    "    allo = np.where(train_ds.classes_frame.loc[:, col] == 1)[0].tolist()\n",
    "    train_ds.classes_frame.loc[allz, col] = epsilon/(K-1)\n",
    "    train_ds.classes_frame.loc[allo, col] = 1-epsilon\n",
    "train_ds.classes_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OrzWMnOI7Os_"
   },
   "outputs": [],
   "source": [
    "cl = []\n",
    "for row in range(train_ds.classes_frame.shape[0]):\n",
    "    cl.append(np.argmax(train_ds.classes_frame.loc[:,train_ds.classes_frame.columns[3:]].loc[row]))\n",
    "\n",
    "temp = pd.DataFrame(cl,columns=['cat'])\n",
    "temp['cat'] = temp['cat'].astype('category')\n",
    "temp['cat'] = temp['cat'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "trn64MgV7RIV"
   },
   "outputs": [],
   "source": [
    "y = torch.from_numpy(temp.values)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "np.arange(len(y)),\n",
    "test_size=0.4,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y)\n",
    "\n",
    "valid_idx, test_idx= train_test_split(\n",
    "np.arange(len(y[valid_idx])),\n",
    "test_size=0.5,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3122 Train_dl: 6 Validation_dl: 2 Unseen_dl: 2\n"
     ]
    }
   ],
   "source": [
    "size = len(train_ds)\n",
    "indices = list(range(size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * size))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "test_split = int(np.floor(VALIDATION_SPLIT * len(train_indices)))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = train_indices[test_split:], train_indices[:test_split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler   = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=train_sampler)\n",
    "val_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=val_sampler)\n",
    "unseen_dl = DataLoader(train_ds,batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=test_sampler)\n",
    "print(\"Total: {} Train_dl: {} Validation_dl: {} Unseen_dl: {}\".format(size, len(train_dl),                                                                    \n",
    "                                                              len(val_dl), len(unseen_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 'val' if only want to evaluate\n",
    "train_or_val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_or_val == 'train':\n",
    "    model = torch.load('./models/gz2_resnet50')\n",
    "    del model.fc[4]\n",
    "    del model.fc[3]\n",
    "    del model.fc[2]\n",
    "    layers = []\n",
    "    layers.append(model.fc[0])\n",
    "    layers.append(model.fc[1])\n",
    "    layers.append(nn.Linear(512, 128))\n",
    "    del model.fc\n",
    "    model.fc = nn.Sequential(*layers)\n",
    "elif train_or_val == 'val':\n",
    "    model = torch.load('./models/efigi_label_smoothin_128')    \n",
    "    del model.fc[6]\n",
    "    del model.fc[5]\n",
    "    del model.fc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.05, nesterov=True, weight_decay=0.0005)\n",
    "criterion = LabelSmoothingCrossEntropy(reduction='mean')\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=3,threshold=0.0001,factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "efigiLSCE = myEfigiLSCE(train_dl, val_dl, unseen_dl, model, optimizer, scheduler, criterion,device=device,BATCH_SIZE=BATCH_SIZE)\n",
    "if train_or_val == 'train':\n",
    "    efigiLSCE.train(n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1249 Test_dl: 4\n"
     ]
    }
   ],
   "source": [
    "test_ds = GalaxiesDataset_rsa(TEST_DIR, TEST_CSV, transform=transformations)\n",
    "#Label smoothing ...\n",
    "cols = test_ds.classes_frame.columns.tolist()[2:]\n",
    "K = 9\n",
    "epsilon = 0.1\n",
    "for col in cols:\n",
    "    allz = np.where(test_ds.classes_frame.loc[:, col] == 0)[0].tolist()\n",
    "    allo = np.where(test_ds.classes_frame.loc[:, col] == 1)[0].tolist()\n",
    "    test_ds.classes_frame.loc[allz, col] = epsilon/(K-1)\n",
    "    test_ds.classes_frame.loc[allo, col] = 1-epsilon\n",
    "test_ds.classes_frame.head(5)\n",
    "size = len(test_ds)\n",
    "indices = list(range(size))\n",
    "test_sampler = SubsetRandomSampler(indices)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=4,\n",
    "                                                 sampler=test_sampler)\n",
    "print(\"Total: {} Test_dl: {}\".format(size, len(test_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on RSA test set beginning:\n",
      "Accuracy on RSA test set: 24.26\n",
      "MAP@R on RSA test set: 0.2993\n"
     ]
    }
   ],
   "source": [
    "res = efigiLSCE.RSAtest(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
