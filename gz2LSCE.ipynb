{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip uninstall -y scikit-learn\n",
    "!pip uninstall -y pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install scikit-learn==0.21.1\n",
    "#!pip install pandas==0.24.2\n",
    "#!pip3 install pandas_ml \n",
    "#!pip3 install pytorch_metric_learning \n",
    "!pip3 install faiss-cpu faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/floyd/home',\n",
       " '/usr/local/lib/python37.zip',\n",
       " '/usr/local/lib/python3.7',\n",
       " '/usr/local/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.7/site-packages',\n",
       " '/usr/local/lib/python3.7/site-packages/xgboost-1.0.2-py3.7.egg',\n",
       " '/usr/local/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " 'pytorch_sol2/']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('pytorch_sol2/')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, time, copy, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pickle\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from config import *\n",
    "from GalaxiesDataset import *\n",
    "from rsa_loader import *\n",
    "from GZ2LSCE import *\n",
    "\n",
    "import pickle\n",
    "from label_smoothing import LabelSmoothingCrossEntropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KowIJ5ipz4Ef"
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers, regularizers\r\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zs1TiAevzPed"
   },
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.Resize((105, 105)),\r\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\r\n",
    "                             transforms.RandomRotation(degrees=(0,360)),\r\n",
    "                             transforms.RandomVerticalFlip(p=0.5),\r\n",
    "                             transforms.ToTensor(),\r\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                                  std=[0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "transformations = transforms.Compose([transforms.Resize((105, 105)),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8q8PZYkJzytk"
   },
   "outputs": [],
   "source": [
    "train_ds = GalaxiesDataset(TRAIN_DIR, TRAIN_CSV, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 9 for 9-class test\n",
    "hubble_classes = 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hubble_classes == 9:\n",
    "    gz2_9 = train_ds.classes_frame.iloc[:, 0:5]\n",
    "    change = gz2_9[gz2_9['hubble_type'].isin(['E0', 'E3-5', 'E7'])].index.tolist()\n",
    "    gz2_9.loc[change, 'hubble_type'] ='E'\n",
    "    dumb = pd.get_dummies(gz2_9['hubble_type'])\n",
    "    train_ds.classes_frame = pd.concat([gz2_9, dumb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>sample</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>dr7objid</th>\n",
       "      <th>hubble_type</th>\n",
       "      <th>E</th>\n",
       "      <th>Irr</th>\n",
       "      <th>S0</th>\n",
       "      <th>SBa</th>\n",
       "      <th>SBb</th>\n",
       "      <th>SBc</th>\n",
       "      <th>Sa</th>\n",
       "      <th>Sb</th>\n",
       "      <th>Sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587722981741363294:</td>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>587722981741363294</td>\n",
       "      <td>Sb</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587722981741363323:</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>587722981741363323</td>\n",
       "      <td>Sc</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587722981741559888:</td>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>587722981741559888</td>\n",
       "      <td>E</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587722981741625481:</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>587722981741625481</td>\n",
       "      <td>Sc</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587722981741625484:</td>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "      <td>587722981741625484</td>\n",
       "      <td>Sb</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 objid    sample  asset_id            dr7objid hubble_type  \\\n",
       "0  587722981741363294:  original         3  587722981741363294          Sb   \n",
       "1  587722981741363323:  original         4  587722981741363323          Sc   \n",
       "2  587722981741559888:  original         5  587722981741559888           E   \n",
       "3  587722981741625481:  original         6  587722981741625481          Sc   \n",
       "4  587722981741625484:  original         7  587722981741625484          Sb   \n",
       "\n",
       "        E     Irr      S0     SBa     SBb     SBc      Sa      Sb      Sc  \n",
       "0  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.9000  0.0125  \n",
       "1  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.9000  \n",
       "2  0.9000  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  \n",
       "3  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.9000  \n",
       "4  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.0125  0.9000  0.0125  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def change(col):\n",
    "cols = train_ds.classes_frame.columns.tolist()[5:]\n",
    "K = hubble_classes\n",
    "epsilon = 0.1\n",
    "for col in cols:\n",
    "    allz = np.where(train_ds.classes_frame.loc[:, col] == 0)[0].tolist()\n",
    "    allo = np.where(train_ds.classes_frame.loc[:, col] == 1)[0].tolist()\n",
    "    train_ds.classes_frame.loc[allz, col] = epsilon/(K-1)\n",
    "    train_ds.classes_frame.loc[allo, col] = 1-epsilon\n",
    "train_ds.classes_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat\n",
       "0    7\n",
       "1    8\n",
       "2    0\n",
       "3    8\n",
       "4    7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl=train_ds.classes_frame['hubble_type'].astype('category').cat.codes.tolist()\n",
    "temp = pd.DataFrame(cl,columns=['cat'])\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(temp.values)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "np.arange(len(y)),\n",
    "test_size=0.4,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y)\n",
    "\n",
    "valid_idx, test_idx= train_test_split(\n",
    "np.arange(len(y[valid_idx])),\n",
    "test_size=0.5,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 239573 Train_dl: 450 Validation_dl: 150 Unseen_dl: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "size = len(train_ds)\n",
    "indices = list(range(size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * size))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "test_split = int(np.floor(VALIDATION_SPLIT * len(train_indices)))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = train_indices[test_split:], train_indices[:test_split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler   = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=train_sampler)\n",
    "val_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=val_sampler)\n",
    "unseen_dl = DataLoader(train_ds,batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=test_sampler)\n",
    "print(\"Total: {} Train_dl: {} Validation_dl: {} Unseen_dl: {}\".format(size, len(train_dl),                                                                    \n",
    "                                                              len(val_dl), len(unseen_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 'val' if only want to evaluate\n",
    "train_or_val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_or_val == 'train':\n",
    "    model = torch.load('./models/gz2_resnet50')\n",
    "    del model.fc[4]\n",
    "    del model.fc[3]\n",
    "    del model.fc[2]\n",
    "    layers = []\n",
    "    layers.append(model.fc[0])\n",
    "    layers.append(model.fc[1])\n",
    "    layers.append(nn.Linear(512, 128))\n",
    "    del model.fc\n",
    "    model.fc = nn.Sequential(*layers)\n",
    "elif train_or_val == 'val':\n",
    "    model = torch.load('./models/gz2_label_smoothing_128')    \n",
    "    del model.fc[6]\n",
    "    del model.fc[5]\n",
    "    del model.fc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.05, nesterov=True, weight_decay=0.0005)\n",
    "criterion = LabelSmoothingCrossEntropy(reduction='mean')\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=3,threshold=0.0001,factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz2LSCE = GZ2LSCE(train_dl, val_dl, unseen_dl, model, optimizer, scheduler, criterion,\n",
    "                  hubble_classes=hubble_classes, device=device,BATCH_SIZE=BATCH_SIZE)\n",
    "if train_or_val == 'train':\n",
    "    gz2LSCE.train(n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hubble_classes == 9:\n",
    "    test_ds = GalaxiesDataset_rsa(TEST_DIR, TEST_CSV, transform=transformations)\n",
    "elif hubble_classes == 11:\n",
    "    test_ds = GalaxiesDataset_rsa(TEST_DIR, './classes/usethis_rsa2.csv', transform=transformations)\n",
    "#Label smoothing ...\n",
    "cols = test_ds.classes_frame.columns.tolist()[2:]\n",
    "K = hubble_classes\n",
    "epsilon = 0.1\n",
    "for col in cols:\n",
    "    allz = np.where(test_ds.classes_frame.loc[:, col] == 0)[0].tolist()\n",
    "    allo = np.where(test_ds.classes_frame.loc[:, col] == 1)[0].tolist()\n",
    "    test_ds.classes_frame.loc[allz, col] = epsilon/(K-1)\n",
    "    test_ds.classes_frame.loc[allo, col] = 1-epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1249 Test_dl: 4\n"
     ]
    }
   ],
   "source": [
    "size = len(test_ds)\n",
    "indices = list(range(size))\n",
    "test_sampler = SubsetRandomSampler(indices)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=4,\n",
    "                                                     sampler=test_sampler)\n",
    "print(\"Total: {} Test_dl: {}\".format(size, len(test_dl)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on RSA test set beginning:\n",
      "Accuracy on RSA test set: 23.7\n",
      "MAP@R on RSA test set: 0.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "res = gz2LSCE.RSAtest(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
