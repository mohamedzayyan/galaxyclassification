{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/floyd/home',\n",
       " '/usr/local/lib/python37.zip',\n",
       " '/usr/local/lib/python3.7',\n",
       " '/usr/local/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.7/site-packages',\n",
       " '/usr/local/lib/python3.7/site-packages/xgboost-1.0.2-py3.7.egg',\n",
       " '/usr/local/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " 'pytorch_sol2/']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('pytorch_sol2/')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, time, copy, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pickle\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from config import *\n",
    "from GalaxiesDataset import *\n",
    "from rsa_loader import *\n",
    "from GZ2DML import *\n",
    "\n",
    "import pickle\n",
    "from label_smoothing import LabelSmoothingCrossEntropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KowIJ5ipz4Ef"
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers, regularizers\r\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zs1TiAevzPed"
   },
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.Resize((105, 105)),\r\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\r\n",
    "                             transforms.RandomRotation(degrees=(0,360)),\r\n",
    "                             transforms.RandomVerticalFlip(p=0.5),\r\n",
    "                             transforms.ToTensor(),\r\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                                  std=[0.229, 0.224, 0.225])])\r\n",
    "\r\n",
    "transformations = transforms.Compose([transforms.Resize((105, 105)),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8q8PZYkJzytk"
   },
   "outputs": [],
   "source": [
    "train_ds = GalaxiesDataset(TRAIN_DIR, TRAIN_CSV, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 9 for 9-class test\n",
    "hubble_classes = 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hubble_classes == 9:\n",
    "    gz2_9 = train_ds.classes_frame.iloc[:, 0:5]\n",
    "    change = gz2_9[gz2_9['hubble_type'].isin(['E0', 'E3-5', 'E7'])].index.tolist()\n",
    "    gz2_9.loc[change, 'hubble_type'] ='E'\n",
    "    dumb = pd.get_dummies(gz2_9['hubble_type'])\n",
    "    train_ds.classes_frame = pd.concat([gz2_9, dumb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat\n",
       "0    7\n",
       "1    8\n",
       "2    0\n",
       "3    8\n",
       "4    7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl=train_ds.classes_frame['hubble_type'].astype('category').cat.codes.tolist()\n",
    "temp = pd.DataFrame(cl,columns=['cat'])\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(temp.values)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "np.arange(len(y)),\n",
    "test_size=0.4,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y)\n",
    "\n",
    "valid_idx, test_idx= train_test_split(\n",
    "np.arange(len(y[valid_idx])),\n",
    "test_size=0.5,\n",
    "shuffle=True,\n",
    "    random_state=42,\n",
    "stratify=y[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 239573 Train_dl: 450 Validation_dl: 150 Unseen_dl: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "size = len(train_ds)\n",
    "indices = list(range(size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * size))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "test_split = int(np.floor(VALIDATION_SPLIT * len(train_indices)))\n",
    "if SHUFFLE_DS:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = train_indices[test_split:], train_indices[:test_split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler   = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=train_sampler)\n",
    "val_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=val_sampler)\n",
    "unseen_dl = DataLoader(train_ds,batch_size=BATCH_SIZE, num_workers=8,\n",
    "                                                 sampler=test_sampler)\n",
    "print(\"Total: {} Train_dl: {} Validation_dl: {} Unseen_dl: {}\".format(size, len(train_dl),                                                                    \n",
    "                                                              len(val_dl), len(unseen_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to 'val' if only want to evaluate\n",
    "train_or_val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_function = 'pair' #'triplet' 'pair'\n",
    "loss = 'pnca' #'triplet' 'contrastive' 'panc' 'pnca' 'normsoftmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_or_val == 'train':\n",
    "    model = torch.load('./models/gz2_label_smoothing_128')    \n",
    "    del model.fc[6]\n",
    "    del model.fc[5]\n",
    "    del model.fc[4]\n",
    "if train_or_val == 'val':\n",
    "    pth = './models/gz2{}_{}_128'.format(mining_function, loss)\n",
    "    model = torch.load(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.05, nesterov=True, weight_decay=0.0005)\n",
    "criterion = LabelSmoothingCrossEntropy(reduction='mean')\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=3,threshold=0.0001,factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz2DML = GZ2DML(train_dl, val_dl, unseen_dl, model, optimizer, scheduler, criterion,mining_function, loss,\n",
    "                  hubble_classes=hubble_classes, device=device,BATCH_SIZE=BATCH_SIZE)\n",
    "if train_or_val == 'train':\n",
    "    gz2DML.train(n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hubble_classes == 9:\n",
    "    test_ds = GalaxiesDataset_rsa(TEST_DIR, TEST_CSV, transform=transformations)\n",
    "elif hubble_classes == 11:\n",
    "    test_ds = GalaxiesDataset_rsa(TEST_DIR, './classes/usethis_rsa2.csv', transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1249 Test_dl: 4\n"
     ]
    }
   ],
   "source": [
    "size = len(test_ds)\n",
    "indices = list(range(size))\n",
    "test_sampler = SubsetRandomSampler(indices)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=4,\n",
    "                                                     sampler=test_sampler)\n",
    "print(\"Total: {} Test_dl: {}\".format(size, len(test_dl)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on RSA test set beginning:\n"
     ]
    }
   ],
   "source": [
    "res = gz2DML.RSAtest(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
